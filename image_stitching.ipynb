{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your images\n",
    "image1 = cv2.imread('XUE-Mountain-Enterance/DSC_0171.jpg')\n",
    "image2 = cv2.imread('XUE-Mountain-Enterance/DSC_0172.jpg')\n",
    "image3 = cv2.imread('XUE-Mountain-Enterance/DSC_0173.jpg')\n",
    "image4 = cv2.imread('XUE-Mountain-Enterance/DSC_0174.jpg')\n",
    "image5 = cv2.imread('XUE-Mountain-Enterance/DSC_0175.jpg')\n",
    "image6 = cv2.imread('XUE-Mountain-Enterance/DSC_0176.jpg')\n",
    "image7 = cv2.imread('XUE-Mountain-Enterance/DSC_0177.jpg')\n",
    "image8 = cv2.imread('XUE-Mountain-Enterance/DSC_0178.jpg')\n",
    "image9 = cv2.imread('XUE-Mountain-Enterance/DSC_0179.jpg')\n",
    "image10 = cv2.imread('XUE-Mountain-Enterance/DSC_0180.jpg')\n",
    "image11 = cv2.imread('XUE-Mountain-Enterance/DSC_0182.jpg')\n",
    "image12 = cv2.imread('XUE-Mountain-Enterance/DSC_0183.jpg')\n",
    "image13 = cv2.imread('XUE-Mountain-Enterance/DSC_0184.jpg')\n",
    "image14 = cv2.imread('XUE-Mountain-Enterance/DSC_0185.jpg')\n",
    "image15 = cv2.imread('XUE-Mountain-Enterance/DSC_0186.jpg')\n",
    "image16 = cv2.imread('XUE-Mountain-Enterance/DSC_0187.jpg')\n",
    "\n",
    "# Resize the images to the same dimensions (optional)\n",
    "width, height = 800, 600  # Adjust the size as needed\n",
    "image1 = cv2.resize(image1, (width, height))\n",
    "image2 = cv2.resize(image2, (width, height))\n",
    "image3 = cv2.resize(image3, (width, height))\n",
    "image4 = cv2.resize(image4, (width, height))\n",
    "image5 = cv2.resize(image5, (width, height))\n",
    "image6 = cv2.resize(image6, (width, height))\n",
    "image7 = cv2.resize(image7, (width, height))\n",
    "image8 = cv2.resize(image8, (width, height))\n",
    "image9 = cv2.resize(image9, (width, height))\n",
    "image10 = cv2.resize(image10, (width, height))\n",
    "image11 = cv2.resize(image11, (width, height))\n",
    "image12 = cv2.resize(image12, (width, height))\n",
    "image13 = cv2.resize(image13, (width, height))\n",
    "image14 = cv2.resize(image14, (width, height))\n",
    "image15 = cv2.resize(image15, (width, height))\n",
    "image16 = cv2.resize(image16, (width, height))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Create a list to store all key points and descriptors\n",
    "keypoints_list = []\n",
    "descriptors_list = []\n",
    "\n",
    "# Iterate through all images and compute key points and descriptors\n",
    "images = [image1, image2, image3, image4, image5, image6, image7, image8, image9, image10, image11, image12, image13, image14, image15, image16, image17]\n",
    "\n",
    "for img in images:\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    keypoints_list.append(keypoints)\n",
    "    descriptors_list.append(descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BFMatcher (Brute Force Matcher) object\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# Match descriptors of the first two images\n",
    "matches = bf.knnMatch(descriptors_list[0], descriptors_list[1], k=2)\n",
    "\n",
    "# Apply ratio test to get good matches\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Sort matches based on their distances\n",
    "good_matches = sorted(good_matches, key=lambda x: x.distance)\n",
    "\n",
    "# Draw the matches (optional)\n",
    "matching_result = cv2.drawMatches(image1, keypoints_list[0], image2, keypoints_list[1], good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the matching points from the good matches\n",
    "src_pts = np.float32([keypoints_list[0][m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints_list[1][m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# Find the homography matrix\n",
    "H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp image2 to align with image1\n",
    "aligned_image2 = cv2.warpPerspective(image2, H, (image1.shape[1], image1.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for the overlapping region\n",
    "mask = np.zeros_like(image1)\n",
    "cv2.fillPoly(mask, [np.int32(dst_pts)], (255, 255, 255))\n",
    "\n",
    "# Blend the two images together\n",
    "result = cv2.addWeighted(image1, 0.5, aligned_image2, 0.5, 0)\n",
    "\n",
    "# Place aligned_image2 onto the result using the mask\n",
    "result = cv2.bitwise_and(result, mask)\n",
    "result += aligned_image2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the result as the first image\n",
    "result = image1\n",
    "\n",
    "# Iterate through the remaining images\n",
    "for i in range(2, len(images) + 1):  # Start from the third image\n",
    "    # Calculate homography\n",
    "    H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    # Warp the current image to align with the result\n",
    "    aligned_image = cv2.warpPerspective(images[i - 1], H, (result.shape[1], result.shape[0]))\n",
    "    \n",
    "    # Create a mask for the overlapping region\n",
    "    mask = np.zeros_like(result)\n",
    "    cv2.fillPoly(mask, [np.int32(dst_pts)], (255, 255, 255))\n",
    "    \n",
    "    # Blend the aligned image with the result\n",
    "    result = cv2.addWeighted(result, 0.5, aligned_image, 0.5, 0)\n",
    "    \n",
    "    # Place the aligned image onto the result using the mask\n",
    "    result = cv2.bitwise_and(result, mask)\n",
    "    result += aligned_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panorama saved as: panorama.jpg\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path where you want to save the panorama\n",
    "output_path = 'panorama.jpg'  # Adjust the filename and path as needed\n",
    "\n",
    "# Save the final panorama image\n",
    "cv2.imwrite(output_path, result)\n",
    "\n",
    "print(\"Panorama saved as:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
